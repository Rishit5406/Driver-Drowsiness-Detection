{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLhR8VgxZGgc"
      },
      "source": [
        "<h1 style=\"text-align:center; color:#4CAF50;\">Driver Drowsiness Detection Using Eye Aspect Ratio (EAR)</h1>\n",
        "\n",
        "<p style=\"font-size:16px; line-height:1.6; text-align:justify;\">\n",
        "This project implements a <strong>driver drowsiness detection system</strong> using advanced computer vision techniques and facial landmarks. By analyzing the <em>Eye Aspect Ratio (EAR)</em>, the system detects prolonged eye closure, which could indicate driver fatigue.\n",
        "</p>\n",
        "\n",
        "<h2 style=\"color:#2196F3;\">Key Features</h2>\n",
        "<ul style=\"font-size:15px;\">\n",
        "  <li>Uses <strong>Dlib's pre-trained model</strong> for facial landmark detection.</li>\n",
        "  <li>Calculates EAR to determine eye openness or closure.</li>\n",
        "  <li>Implements a <strong>sliding window mechanism</strong> to track eye states over time.</li>\n",
        "  <li>Alerts the user upon detecting drowsiness patterns.</li>\n",
        "</ul>\n",
        "\n",
        "<h2 style=\"color:#FF5722;\">Technologies Used</h2>\n",
        "<ul style=\"font-size:15px;\">\n",
        "  <li><strong>OpenCV</strong> for video frame processing.</li>\n",
        "  <li><strong>Dlib</strong> for face and eye landmark detection.</li>\n",
        "  <li><strong>Python</strong> for computational logic and integration.</li>\n",
        "</ul>\n",
        "\n",
        "<p style=\"font-size:16px; line-height:1.6; text-align:center; color:#757575;\">\n",
        "Run the code block below to initialize the system and start detecting driver drowsiness.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSJQH1y3P_ab"
      },
      "outputs": [],
      "source": [
        "# Our Setup, Import Libaries, Create our Imshow Function\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "\n",
        "# Importing Land-mark Model\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# Configuration and Constants\n",
        "EYE_AR_THRESH = 0.22  # Threshold for Eye Aspect Ratio (EAR) to determine eye closure\n",
        "SLIDING_WINDOW_SIZE = 100  # Number of frames considered in the sliding window\n",
        "CLOSED_THRESHOLD = 0.4  # 40% of frames with closed eyes triggers an alert\n",
        "SLEEP_THRESHOLD=0.8\n",
        "VIDEO_PATH = 'Video.mp4'  # Path to the input video file\n",
        "LANDMARKS_MODEL = \"shape_predictor_68_face_landmarks.dat\"  # Path to dlib's pre-trained landmarks model\n",
        "\n",
        "# Eye Aspect Ratio (EAR) Calculation\n",
        "def calculate_eye_aspect_ratio(eye_points):\n",
        "    \"\"\"\n",
        "    Calculate the Eye Aspect Ratio (EAR) to determine if an eye is open or closed.\n",
        "    EAR is based on the distances between horizontal and vertical eye landmarks.\n",
        "    \"\"\"\n",
        "    # Vertical distances\n",
        "    A = np.linalg.norm(np.array(eye_points[1]) - np.array(eye_points[5]))\n",
        "    B = np.linalg.norm(np.array(eye_points[2]) - np.array(eye_points[4]))\n",
        "    # Horizontal distance\n",
        "    C = np.linalg.norm(np.array(eye_points[0]) - np.array(eye_points[3]))\n",
        "    # EAR formula\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "# Process detected faces to compute EAR for both eyes\n",
        "def process_faces(gray_frame, faces, shape_predictor):\n",
        "    \"\"\"\n",
        "    For each detected face, extract the landmarks and compute EAR for both eyes.\n",
        "    Returns a list of EAR tuples (left_ear, right_ear) for all detected faces.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for face in faces:\n",
        "        landmarks = shape_predictor(gray_frame, face)\n",
        "        # Get coordinates for the left and right eyes\n",
        "        left_eye_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]\n",
        "        right_eye_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]\n",
        "        # Calculate EAR for both eyes\n",
        "        left_ear = calculate_eye_aspect_ratio(left_eye_points)\n",
        "        right_ear = calculate_eye_aspect_ratio(right_eye_points)\n",
        "        results.append((left_ear, right_ear))\n",
        "    return results\n",
        "\n",
        "# Initialize Dlib Models\n",
        "try:\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "    shape_predictor = dlib.shape_predictor(LANDMARKS_MODEL)\n",
        "except Exception as e:\n",
        "    print(f\"Error: Unable to load the landmarks model ({LANDMARKS_MODEL}). Please verify the file path.\")\n",
        "    print(e)\n",
        "    exit()\n",
        "\n",
        "# Open Video File\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video file ({VIDEO_PATH}). Please verify the file path.\")\n",
        "    exit()\n",
        "\n",
        "# Variables for Tracking\n",
        "closed_frames = []  # Sliding window to track frames where eyes are closed\n",
        "frame_count = 1  # Frame counter within each second\n",
        "sec_count = 1  # Second counter for video playback\n",
        "\n",
        "# Process video frame-by-frame\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # End of video\n",
        "\n",
        "    # Convert the frame to grayscale for face detection\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # Detect faces in the current frame\n",
        "    faces = face_detector(gray)\n",
        "    both_eyes_closed = False  # Flag to track if both eyes are closed\n",
        "\n",
        "    # Process each detected face\n",
        "    for left_ear, right_ear in process_faces(gray, faces, shape_predictor):\n",
        "        # Determine the state of each eye based on EAR threshold\n",
        "        left_eye_closed = left_ear < EYE_AR_THRESH\n",
        "        right_eye_closed = right_ear < EYE_AR_THRESH\n",
        "        both_eyes_closed = left_eye_closed and right_eye_closed\n",
        "        print(\"\")\n",
        "\n",
        "        # Logging based on eye states\n",
        "        if both_eyes_closed:\n",
        "            print(f\"{sec_count}, Status: Both eyes closed.\", end=\" \")\n",
        "        elif not left_eye_closed and not right_eye_closed:\n",
        "            print(f\"{sec_count}, Status: Both eyes open.\", end=\" \")\n",
        "        elif left_eye_closed and not right_eye_closed:\n",
        "            print(f\"{sec_count}, Status: Left eye closed, right eye open.\", end=\" \")\n",
        "        elif not left_eye_closed and right_eye_closed:\n",
        "            print(f\"{sec_count}, Status: Left eye open, right eye closed.\", end=\" \")\n",
        "\n",
        "    # Update the sliding window with the current frame's eye state\n",
        "    closed_frames.append(both_eyes_closed)\n",
        "    if len(closed_frames) > SLIDING_WINDOW_SIZE:\n",
        "        closed_frames.pop(0)\n",
        "\n",
        "    # Check for drowsiness based on sliding window\n",
        "    if len(closed_frames) == SLIDING_WINDOW_SIZE:\n",
        "        closed_ratio = sum(closed_frames) / SLIDING_WINDOW_SIZE\n",
        "        if closed_ratio >= CLOSED_THRESHOLD and closed_ratio<=SLEEP_THRESHOLD:\n",
        "            print(f\"ALERT: High drowsiness detected!\", end=\" \")\n",
        "        elif closed_ratio > SLEEP_THRESHOLD:\n",
        "            print(f\"ALERT: Driver Sleeping\", end=\" \")\n",
        "        else:\n",
        "            print(f\"Driver Awake\", end=\" \")\n",
        "        print(f\"{int(closed_ratio*100)}% Drowsiness\", end=\" \")\n",
        "\n",
        "    # Increment frame and second counters\n",
        "    frame_count += 1\n",
        "    if frame_count > 30:  # Assuming 30 FPS\n",
        "        frame_count = 1\n",
        "        sec_count += 1\n",
        "\n",
        "    # Exit the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources and clean up\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
